{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.5 Metryki specyficzne dla klasyfikacji binarnej\n",
    "Stworzyliśmy w poprzednim pliku prosty model który klasyfikował nam punkty na podstawie jednej tylko cechy. Byliśmy w stanie graficznie dostrzec jak model będzie klasyfikował nowe przykłady, ale w jaki sposób moglibyśmy sprawdzić model, gdyby cech było więcej? Musimy znać metody, które pozwolą nam zmierzyć jakość stworzonego systemu i dodatkowo będziemy mogli na ich podstawie wybrać najlepszy, jeśli akurat będziemy porównywać kilka różnych rozwiązań."
   ],
   "id": "fe65d24053663769"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Przykład klasyfikacji medycznej\n",
    "Załóżmy, że tworzymy system, który ma na celu diagnozować pacjentów na podstawie ich wyników badań. Nie będzie to system ogólnego użytku, ale diagnozujący jedną konkretną chorobę, np. pewien specyficzny typ nowotworu. Klasą pozytywną będzie tutaj obecność tego schorzenia. Wyjątkowo, nie będziemy skupiać się na cechach i ich sposobach wykorzystania przez model, a jedynie stworzymy sobie pięć przykładów modeli, które będą popełniały innego rodzaju błędy i zobaczymy jak przełoży się to na wartość poszczególnych metryk.\n",
    "\n",
    "Na potrzeby tego eksperymentu zakładamy, że mamy zbiór testowy opisujący 1000 pacjentów, a choroba dotyka 1,7% pacjentów, tj. w naszej próbie powinno być 17 takich osób. Skorzystamy jednak z generatora liczb pseudolosowych, aby wygenerować sobie takie dane."
   ],
   "id": "101b48785d8238e6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T13:59:44.423204Z",
     "start_time": "2024-08-28T13:59:44.003930Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T13:59:45.461110Z",
     "start_time": "2024-08-28T13:59:45.449293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(63)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"real_class\": np.random.choice([0, 1], size=1000, p=[.983, .017])\n",
    "})\n",
    "predictions_df[\"real_class\"].value_counts()"
   ],
   "id": "a66c58f1610cf06a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real_class\n",
       "0    982\n",
       "1     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Musimy wprowadzić sobie kilka pojęć, które często będą przewijać się w pracy z metodami ML. Pod pojęciem confusion matrix (pol. tablica pomyłek) kryje się forma prezentacji predykcji dla modelu klasyfikacji binarnej.",
   "id": "2f45380e845f0f02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T13:57:57.949554Z",
     "start_time": "2024-08-28T13:57:57.178757Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import confusion_matrix",
   "id": "20bef987cb85fccf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Model zupełnie losowy\n",
    "W naszym problemie mamy dwie klasy i podstawowym podejściem może być stworzenie modelu, który losowo zwraca wartość 0 lub 1, nie zwracając przy tym uwagi na rzeczywiste częstotliwości występowania."
   ],
   "id": "42869e740733638c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:10:47.443448Z",
     "start_time": "2024-08-28T14:10:47.434599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df['pred_a'] = np.random.choice([0, 1], size=1000, p=[.5, .5])\n",
    "predictions_df.sample(5)"
   ],
   "id": "d798e927ba0f39d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     real_class  pred_a\n",
       "370           0       0\n",
       "688           0       1\n",
       "403           0       0\n",
       "726           0       1\n",
       "921           0       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_class</th>\n",
       "      <th>pred_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:16:37.993814Z",
     "start_time": "2024-08-28T14:16:37.979901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random = confusion_matrix(predictions_df[[\"real_class\"]], predictions_df['pred_a'])\n",
    "random"
   ],
   "id": "c2456c42c60d7c8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[473, 509],\n",
       "       [  8,  10]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* 473 - liczba pacjentów których model stwierdził że nie są chorzy i faktycznie nie są\n",
    "* 509 - liczba pacjentów których model stwierdził że są chorzy i a tak naprawdę nie są\n",
    "* 8 - liczba pacjentów których model stwierdził że nie są chorzy a tak naprawdę są\n",
    "* 10 - liczba pacjentów których model stwierdził że są chorzy i faktycznie są"
   ],
   "id": "dccd161e79edd03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Model losowy ważony\n",
    "Znamy częstotliwość występowania choroby w populacji, więc możemy też stworzyć drugi model który będzie również losowo generował odpowiedzi, ale uwzględniając tę wartość."
   ],
   "id": "b41e16bca770dd9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:18:52.747771Z",
     "start_time": "2024-08-28T14:18:52.737495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df['pred_b'] = np.random.choice([0, 1], size=1000, p=[.983, .017])\n",
    "predictions_df.sample(5)"
   ],
   "id": "f04d0ab0b250066e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     real_class  pred_a  pred_b\n",
       "493           0       1       0\n",
       "531           0       0       0\n",
       "171           0       1       0\n",
       "596           0       1       0\n",
       "210           0       1       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_class</th>\n",
       "      <th>pred_a</th>\n",
       "      <th>pred_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:19:26.107941Z",
     "start_time": "2024-08-28T14:19:26.100802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conf_matrix_b = confusion_matrix(predictions_df[[\"real_class\"]], predictions_df[\"pred_b\"])\n",
    "conf_matrix_b"
   ],
   "id": "61c106440b17d267",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[966,  16],\n",
       "       [ 17,   1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Model negatywny",
   "id": "92401659f2d03e68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:28:35.600861Z",
     "start_time": "2024-08-28T14:28:35.586902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df[\"pred_c\"] = np.random.choice([0, 1], size=1000, p=[1, 0])\n",
    "conf_matrix_c = confusion_matrix(predictions_df[[\"real_class\"]], predictions_df[\"pred_c\"])\n",
    "conf_matrix_c"
   ],
   "id": "9ebc30172de689d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[982,   0],\n",
       "       [ 18,   0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Skuteczność modelu na poziomie:",
   "id": "3f145a9d0d0d1ce5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:29:12.316033Z",
     "start_time": "2024-08-28T14:29:12.309969Z"
    }
   },
   "cell_type": "code",
   "source": "982/1000",
   "id": "8ea287149464dbf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Około 98,2% ;D",
   "id": "809036c22035605b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Model pozytywny",
   "id": "fccc65e87d09327e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:32:42.069234Z",
     "start_time": "2024-08-28T14:32:42.060223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df[\"pred_d\"] = np.random.choice([0, 1], size=1000, p=[0, 1])\n",
    "conf_matrix_d = confusion_matrix(predictions_df[[\"real_class\"]], predictions_df[\"pred_d\"])\n",
    "conf_matrix_d"
   ],
   "id": "786241c6e96b1cf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 982],\n",
       "       [  0,  18]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Skuteczność na poziomie... 1,8% ;D",
   "id": "cdfb0cf01b8912a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Model kontrolny\n",
    "Stwórzmy też, poza wszystkimi poprzednimi przypadkami, jeden model kontrolny, który hipotetycznie mógłby zostać nauczony w projekcie ML. Nie będzie on działał idealnie, ale do jego wygenerowania wykorzystamy rzeczywiste klasy każdej z obserwacji."
   ],
   "id": "de7886bf6e336a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:43:51.661894Z",
     "start_time": "2024-08-28T14:43:51.655470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df[\"pred_e\"] = predictions_df[\"real_class\"] \\\n",
    "    .where(np.random.random(size=1000) < 0.95, 1-predictions_df[\"real_class\"])\n",
    "predictions_df.sample(5)"
   ],
   "id": "5b42e02b7a7ff5ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     real_class  pred_a  pred_b  pred_c  pred_d  pred_e\n",
       "253           0       1       0       0       1       0\n",
       "987           1       0       0       0       1       1\n",
       "397           0       1       0       0       1       0\n",
       "994           0       1       0       0       1       0\n",
       "950           0       0       0       0       1       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_class</th>\n",
       "      <th>pred_a</th>\n",
       "      <th>pred_b</th>\n",
       "      <th>pred_c</th>\n",
       "      <th>pred_d</th>\n",
       "      <th>pred_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "predictions_df[[\"real_class\"]] <- to jest dataframe, predictions_df[\"real_class\"] <- to jest data Series",
   "id": "d5c728e7a6848731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:56:59.971517Z",
     "start_time": "2024-08-28T14:56:59.964078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conf_matrix_e = confusion_matrix(predictions_df[\"real_class\"], predictions_df[\"pred_e\"])\n",
    "conf_matrix_e"
   ],
   "id": "ed6395b329e90c30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[934,  48],\n",
       "       [  0,  18]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T14:58:41.580282Z",
     "start_time": "2024-08-28T14:58:41.576315Z"
    }
   },
   "cell_type": "code",
   "source": "model_columns = [\"a\", \"b\", \"c\", \"d\", \"e\"]",
   "id": "81e84cec7c359eac",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Przegląd metryk klasyfikacji binarnej",
   "id": "e283e85cbec4a1e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Accuracy\n",
    "Jest to najprostsza z metryk i bardzo intuicyjna, stąd też dość powszechna. Definiuje się ją jako stosunek prawidłowych predykcji, w stosunku do wszystkich predyckji.\n",
    "accuracy = TP + TN / TP + FP + FN + TP"
   ],
   "id": "4672a93d0c69fb57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:01:52.090686Z",
     "start_time": "2024-08-28T15:01:52.086198Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score",
   "id": "261de64d393646ef",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:02:59.421635Z",
     "start_time": "2024-08-28T15:02:59.407719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_columns:\n",
    "    print(\n",
    "        f\"Model {model}:\",\n",
    "        accuracy_score(predictions_df[\"real_class\"], predictions_df[f\"pred_{model}\"])\n",
    "    )"
   ],
   "id": "e7d94fcf656dbae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a: 0.483\n",
      "Model b: 0.967\n",
      "Model c: 0.982\n",
      "Model d: 0.018\n",
      "Model e: 0.952\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Okazuje się, że model który jest zawsze negatywny, ma największą wydajność liczoną za pomocą metryki accuracy. Metryki tej używamy głównie dla zbalansowanych zbiorów i wtedy, gdy chcemy być w stanie wyjaśnić wszystkim jak dobry jest nasz model.",
   "id": "40dd7e391028e68a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Precision**\n",
    "Miara ta wyznacza jak wiele obserwacji oznaczonych jako pozytywne, jest rzeczywiście pozytywne. W przypadku diagnozy naszej choroby, jest to stosunek liczby pacjentów poprawnie zdiagnozowanych jako chorzy, w stosunku do liczby wszystkich osób dla których system przewidział klasę pozytywną.\n",
    "* precision = TP / TP + FP"
   ],
   "id": "bca60189e53588d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:07:38.231789Z",
     "start_time": "2024-08-28T15:07:38.227749Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import precision_score",
   "id": "2463f13c5187d82f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:08:55.266095Z",
     "start_time": "2024-08-28T15:08:55.233003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_columns:\n",
    "    print(f\"Model {model}: \",\n",
    "          precision_score(predictions_df[\"real_class\"], predictions_df[f\"pred_{model}\"]))"
   ],
   "id": "a9f9bcd6fc4a0473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a:  0.019267822736030827\n",
      "Model b:  0.058823529411764705\n",
      "Model c:  0.0\n",
      "Model d:  0.018\n",
      "Model e:  0.2727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Recall / Sensivity\n",
    "Jeśli chcielibyśmy obliczyć jak wiele elementów rzeczywiście pozytywnych zostało przez nas poprawnie zaklasyfikowane jako pozytywne, to recall jest odpowiednią metryką. W naszym przykładzie, zależałoby nam na wyłapaniu każdego chorego, ale nie zwracamy uwagi na to czy zdrowych pacjentów zaklasyfikujemy również jako chorych.\n",
    "* recall = TP / TP + FN"
   ],
   "id": "da3a91e166b26f56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:16:19.940349Z",
     "start_time": "2024-08-28T15:16:19.935179Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import recall_score",
   "id": "8925bf9973b37d40",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:16:44.380123Z",
     "start_time": "2024-08-28T15:16:44.361516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_columns:\n",
    "    print(f\"Model {model}: \",\n",
    "          recall_score(predictions_df[\"real_class\"], predictions_df[f\"pred_{model}\"]))"
   ],
   "id": "9ec565fc71dff00d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a:  0.5555555555555556\n",
      "Model b:  0.05555555555555555\n",
      "Model c:  0.0\n",
      "Model d:  1.0\n",
      "Model e:  1.0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### F-Score\n",
    "Metryki precision i recall mogą być naszym celem optymalizacji również łącznie. Jak porównać dwa modele na podstawie dwóch wartości? F-Score jest odpowiedzią, ponieważ łączy obie metryki.\n",
    "* f score = (1 + Beta)^2 precision * recall / Beta^2 * precision + recall\n",
    "* Za pomocą parametru Beta możemy sterować wagami każdej z metryki, im wyższa wartość B tym bardziej dbamy o optymalizacje metryki recall. Typowo stosuje się metrykę *F1* oraz *F2*, gdzie parametr B jest ustawiony kolejno na 1 i 2. "
   ],
   "id": "1921134a51030bb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:22:01.700729Z",
     "start_time": "2024-08-28T15:22:01.696637Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import fbeta_score",
   "id": "38e8b59e799f633",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:23:56.421119Z",
     "start_time": "2024-08-28T15:23:56.399539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_columns:\n",
    "    print(f\"Model {model}: \",\n",
    "          fbeta_score(predictions_df[\"real_class\"], predictions_df[f\"pred_{model}\"],beta = 1))"
   ],
   "id": "21bf4a4c6527f5e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a:  0.037243947858473\n",
      "Model b:  0.05714285714285714\n",
      "Model c:  0.0\n",
      "Model d:  0.03536345776031434\n",
      "Model e:  0.42857142857142855\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Szukanie optymalnego modelu\n",
    "Znajomość problemu może zasugerować nam na jakiego rodzaju błędy możemy się zgodzić. Machine learning jest w stanie stworzyć modele, które będą najczęściej poprawne, jednak nie będą one perfekcyjne. Wybór odpowiedniej metryki pozwala wybrać model, który popełnia głównie nieszkodliwe dla nas pomyłki."
   ],
   "id": "68d4daea7a05adff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:26:45.263159Z",
     "start_time": "2024-08-28T15:26:45.258845Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import classification_report",
   "id": "e2c0c6e2e72367af",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:28:51.102455Z",
     "start_time": "2024-08-28T15:28:51.043065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_columns:\n",
    "    print(f\"Model {model}: \\n\",\n",
    "          classification_report(predictions_df[\"real_class\"], predictions_df[f\"pred_{model}\"]))"
   ],
   "id": "f6a52d35d84fc1a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.65       982\n",
      "           1       0.02      0.56      0.04        18\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.50      0.52      0.34      1000\n",
      "weighted avg       0.97      0.48      0.64      1000\n",
      "\n",
      "Model b: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       982\n",
      "           1       0.06      0.06      0.06        18\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.52      0.52      0.52      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Model c: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       982\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.49      0.50      0.50      1000\n",
      "weighted avg       0.96      0.98      0.97      1000\n",
      "\n",
      "Model d: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       982\n",
      "           1       0.02      1.00      0.04        18\n",
      "\n",
      "    accuracy                           0.02      1000\n",
      "   macro avg       0.01      0.50      0.02      1000\n",
      "weighted avg       0.00      0.02      0.00      1000\n",
      "\n",
      "Model e: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       982\n",
      "           1       0.27      1.00      0.43        18\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.64      0.98      0.70      1000\n",
      "weighted avg       0.99      0.95      0.97      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/maciej/deep/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2aa60bb5e2c617a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
